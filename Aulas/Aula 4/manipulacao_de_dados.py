# -*- coding: utf-8 -*-
"""manipulacao_de_dados.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TQ1qC-l1DAbXAA2e2Y3-vgzEkHSfORaa

## **Pandas Essencial**
**Prof. Dr. Samuel Martins (@hisamuka @xavecoding)** <br/>
xavecoding: https://youtube.com/c/xavecoding <br/>

Neste tutorial, vamos aprender o essencial da biblioteca _Pandas_ para manipulação de dados.<br/><br/>

<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.

### Pacotes usados neste Notebook
"""

# pacotes usados neste notebook
import pandas as pd

from google.colab import drive
from google.colab import files
drive.mount ('/content/gdrive', force_remount = True)
dirRaiz = "/content/gdrive/My Drive/"
dirBase = dirRaiz + "Colab Notebooks/"

"""<h1>Manipulação de Dados com Pandas</h1><hr/>

<h2>1. Manipulação Básica de Datasets</h2>
<hr/>

**Dataset**: Gas Prices in Brazil: https://www.kaggle.com/matheusfreitag/gas-prices-in-brazil <br/>

Este dataset contém os **registros dos preços médios semanais dos combustíveis do Brasil entre os anos de 2004 e 2019**. <br/>
Cada *observação (registro/linha)* consiste em um registro de preço aferido para um dado tipo de combustível em uma dada localidade do Brasil. <br/>
Alguns dos principais *atributos* (colunas) do dataset são: 'ESTADO', 'PRODUTO', 'NÚMERO DE POSTOS PESQUISADOS', 'PREÇO MÉDIO REVENDA'.


\* O arquivo disponibilizado no Kaggle está no formato *tsv*. Embora o _pandas_ consiga abri-lo normalmente, convertemos o arquivo para o formato *CSV*, que é um dos formatos mais utilizados, e mudamos seu separador para ';' apenas para mostrar algumas opções da função de carregamento.

### 1.1. Importando o Dataset
Para carregar um dataset no formato csv, basta utilizar a função `read_csv` do pandas. Por padrão, ela considera _','_ como separador.
"""

data = pd.read_csv(dirBase+'/datasets/GasPricesinBrazil_2004-2019.csv')

data

"""O dataset não foi carregado corretamente pois o separador utilizado seu arquivo CSV era ';' e não a ','. <br/>
Vamos então carregá-lo corretamente:
"""

# carregando o dataset corretamente ==> neste caso, usa o separador ';'
data = pd.read_csv(dirBase+'/datasets/GasPricesinBrazil_2004-2019.csv', sep=';')

data

"""### 1.2. Exibindo as primeiras linhas do Dataset
A função `.head()` exibe as 5 primeiras linhas do dataset/tabela/Data Frame.
"""

data.head()

# exibe as 10 primeiras linhas do dataframe
data.head(10)

"""### 1.3 Informações do Dataset e Elementos Chave

### 1.3.1 Informações gerais sobre o Dataset
"""

data.info()

"""A primeira coluna da tabela, chamada _'Unnamed: 0'_, parece não significar nada. Na verdade, ela parece conter os **índices** da tabela, que foram salvos como uma _coluna_.<br/>
Veremos em seguida como **remover tal coluna**.

Outro ponto é que, aparentemente, nenhum atributo/coluna possui valores nulos (_null_), uma vez que o número de registros do dataframe e os números de valores _non-null_ é de **106823**. <br/>
Mas, veremos que não é bem assim para esse caso.

Além disso, notem que alguns atributos/colunas, p. ex., 'PREÇO MÉDIO DISTRIBUIÇÃO', possuem tipo de dado `object` em vez de `float`. Esse `object`, comumente, indica uma string. Isso parece estranho e suspeito. Veremos se isso é problemático mais pra frente.

### 1.3.2 Data Frame
Todo dataset carregado (dados estruturados) é um `Data Frame`: 'Tabela' bi-dimensional, de tamanho mutável, com dados potencialmente heterogêneos. <br/>
"""

type(data)

"""Podemos acessar as **dimensões do Data Frame** (número de linhas x número de colunas) utilizando o atributo `.shape` do Data Frame."""

data.shape

print(f'O DataFrame possui {data.shape[0]} linhas/observações/registros e {data.shape[1]} colunas/atributos/variáveis.')

"""#### **Criando um DataFrame**

Podemos criar um DataFrame a partir de um _dicionário_, onde cada **chave** possui uma **lista de elementos de igual tamanho**.<br/>
As **chaves** representam as **colunas** e **cada um dos valores de sua lista** representa o **valor da linha** correspondente para aquela coluna.
"""

personagens_df = pd.DataFrame({
    'nome': ['Luke Skywalker', 'Yoda', 'Palpatine'],
    'idade': [16, 1000, 70],
    'peso': [70.5, 15.2, 60.1],
    'eh jedi': [True, True, False]  # o nome das colunas podem ter espaços
})

personagens_df

personagens_df.info()

"""#### **VEJA MAIS**
Criando um Data Frame a partir de um dicionário: https://www.geeksforgeeks.org/how-to-create-dataframe-from-dictionary-in-python-pandas/

#### **Renomeando as colunas de um DataFrame**
**===>** O atributo `DataFrame.columns` retorna uma "lista" com os **nomes de todas as colunas** do data frame.
"""

personagens_df.columns

type(personagens_df.columns)

list(personagens_df.columns)

"""<br/>

**===>** Para **renomear colunas** do data frame, utilize o método `DataFrame.rename`, que retorna uma _cópia_ do data frame com as as colunas renomeadas:
"""

personagens_df

personagens_df_renomeado = personagens_df.rename(columns={
    'nome': 'Nome Completo',  # renomeia a coluna de nome 'nome' para 'Nome Completo'
    'idade': 'Idade'
})

personagens_df_renomeado

personagens_df

"""Para renomear o _próprio_ data frame em questão, utilize o parâmetro `inplace=True`:"""

personagens_df.rename(columns={'NOME': 'Nome Completo','idade': 'Idade'}, inplace=True)

personagens_df

"""<br/>

**===>** Uma outra forma de **renomear todas as colunas** de um data frame é passar uma _lista_ com os novos nomes das colunas para o atributo `DataFrame.columns`:
"""

personagens_df.columns

personagens_df.columns = ['NOME', 'IDADE', 'PESO', 'EH_JEDI']

personagens_df

"""### 1.3.3 Series

Array uni-dimensional com os dados e rótulos de um eixo.
"""

data.head()

# selecionando uma coluna inteira
data['ESTADO']

# selecionando uma coluna inteira
# esta forma de acesso, só funciona para colunas com nomes sem espaços, acentos, etc (caracteres inválidos)
data.ESTADO

type(data['ESTADO'])

# selecionando a observação indexada no índice [1] do dataframe
data.iloc[1]

type(data.iloc[1])

"""#### **Criando uma Series**

Podemos criar um DataFrame a partir de uma lista de elementos.
"""

pd.Series([5.5, 6.0, 9.5])

"""Podemos alterar o **nome dos índices** (veremos melhor em seguida) e o **nome da Series** (o que ela representa):"""

pd.Series([5.5, 6.0, 9.5], index=['prova 1', 'prova 2', 'projeto'], name='Notas dos Luke Skywalker')

"""#### **VEJA MAIS**
https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html

### 1.3.4 Atribuindo Dados
"""

data.head()

"""#### 1.3.4.1 Atribuindo constantes"""

produto_view = data['PRODUTO']  # a series retornada refente à coluna, NÃO É UMA CÓPIA, mas sim, uma REFERÊNCIA/VIEW à coluna do dataframe
produto_view

produto_copy_bkp = data['PRODUTO'].copy()  # retorna uma cópia da coluna 'PRODUTO'
produto_copy_bkp

data['PRODUTO'] = 'Combustível'  # atribuindo o valor constante 'Combustível' para linha do dataframe na coluna 'PRODUTO'

data.head()

produto_view

produto_copy_bkp

"""#### 1.3.4.2 Atribuindo listas ou series"""

nrows, ncols = data.shape
nrows, ncols

novos_produtos = [f'Produto {i}' for i in range(nrows)]
len(novos_produtos)

# a quantidade de elementos da lista `novos_produtos` é igual ao número de linhas do dataframe
data['PRODUTO'] = novos_produtos

data

print(produto_view)
print('\n')
print(produto_copy_bkp)

# voltando para os produtos originais
data['PRODUTO'] = produto_copy_bkp  # produto_copy_bkp é uma Series

data

"""#### 1.3.4.3 Criando novas colunas
Para **criar uma nova coluna** em um data frame, basta atribuirmos uma _lista/Series de valores_ ou uma constante a uma **nova 'chave'** do data frame. <br/>

**PS:** A _quantidade de valores_ da lista precisa ser **igual** ao _número de linhas/registros_ do data frame.
"""

# criando uma coluna a partir de um valor constante/default
# todas as linhas terão o mesmo valor para esta nova coluna
data['coluna sem nocao'] = 'DEFAULT'
data

data['coluna a partir de lista'] = range(data.shape[0])

data

# não funciona pq a quantidade de elementos da lista (a serem atribuídos a nova coluna) é diferente
# da quantidade de linhas do dataframe
data['nao funciona'] = [1, 2, 3]

"""<br/>

Outro exemplo:
"""

data.head()

data['PREÇO MÉDIO REVENDA (dólares)'] = data['PREÇO MÉDIO REVENDA'] * 6.0

data

"""**PS:** Obviamente, a lógica correta em converter o preço dos combustíveis em reais para dólares não é considerar uma taxa de câmbio fixa, uma vez que cada preço em real foi aferido em um momento diferente.

### 1.3.4 Índices

Todo Data Frame possui **índices**, que não são considerado colunas da tabela. Tais índices são comumente **númericos**, de 0 a num_linhas-1, mas também podem ser **textuais (rótulos/labels)**.
"""

data

data.index

"""Use `list(data.index)` ou `data.index.to_list()` para converter um RangeIndex para uma python list.

#### **Exemplo de Data Frame com Índices Textuais (labels)**
"""

pesquisa_de_satisfacao = pd.DataFrame({
    'bom': [50, 21, 100],
    'ruim': [131, 2, 30],
    'pessimo': [30, 20, 1]
}, index=['XboxOne', 'Playstation4', 'Switch'])

pesquisa_de_satisfacao.head()

pesquisa_de_satisfacao.index

"""### 1.4 Selecionando uma ou mais observações (Indexação)"""

data.head()

"""#### **==>  Index-based selection (seleção baseada em Índices)**
Mostrando linhas específicas de um DataFrame:

`iloc`: seleciona elementos do Dataframe, baseado em seu **índice (número)** --> row-first, column-second

**Selecionando uma observação/linha:**
"""

# selecionando a linha 1 ===> observação de índice [1] do dataframe
data.iloc[1]

"""**Selecionando múltiplas observações/linhas:**"""

# selecionando as linhas de índice de 0 a 5 (incluso)
data.iloc[:6]

# selecionando as linhas de índice de 10 a 15 (incluso)
data.iloc[10:16]

# selecionando as linhas/observações de índice 1, 5, 10, 15
data.iloc[[1, 5, 10, 15]]

# selecionando as linhas/observações de índices 5, 1, 15, 10
data.iloc[[5, 1, 15, 10]]

# retornar o valor da linha de índice 1, coluna 4 ('ESTADO')
data.iloc[1, 4]

# e assim por diante!

"""#### **==>  Label-based selection (seleção baseadas em Rótulos)**

`loc`: seleciona elementos do Dataframe, baseado em seus **rótulos** --> row-first, column-second
"""

pesquisa_de_satisfacao

# retorna a linha de índice 0 (implícito)  ==> usando o iloc
pesquisa_de_satisfacao.iloc[0]

# retorna o valor da linha de índice 0 (implícito) e coluna de índice 1 (implícito)  ==> usando o iloc
pesquisa_de_satisfacao.iloc[0, 1]

# retorna a linha cujo o rótulo do índice é 'XboxOne'
pesquisa_de_satisfacao.loc['XboxOne']

# NÃO FUNCIONA ===> iloc tentando acessar índices com rótulos
pesquisa_de_satisfacao.iloc['XboxOne']

# NÃO FUNCIONA ===> loc tentando acessar índices rotulados com números
pesquisa_de_satisfacao.loc[0]

pesquisa_de_satisfacao

# retorna o valor da linha 'Playstation4', coluna 'ruim'
pesquisa_de_satisfacao.loc['Playstation4', 'ruim']

# selecionando as linhas de índices rotulados 'XboxOne', 'Switch'
pesquisa_de_satisfacao.loc[['XboxOne', 'Switch']]

# retorna todas as linhas e apenas as colunas com rótulos 'bom' e 'pessimo'
pesquisa_de_satisfacao[['bom', 'pessimo']]

# retorna todas as linhas e apenas as colunas com rótulos 'bom' e 'pessimo'
pesquisa_de_satisfacao.loc[:, ['bom', 'pessimo']]

"""#### OBSERVAÇÃO
**Índices Númericos**, por default, possuem **rótulos que correspondem aos seus valores númericos.**
"""

data.head()

data.iloc[1]

data.loc[1]

"""### 1.5 Selecionando um ou mais atributos (colunas)"""

data.head()

# retornando a coluna/atributo 'ESTADO'
data['ESTADO']

data.ESTADO

data.loc[:, 'ESTADO']

# a forma de acesso de colunas por .NOME_DA_COLUNA só funciona se
# NOME_DA_COLUNA não possuir caracteres inválidos (espaços, acentos, cedilha, ...)
### não funciona
# data.DATA INICIAL

# para colunas cujos rótulos possuem caracteres inválidos,
# apenas a seleção via string é válida
data['DATA INICIAL']

"""Como o rótulo da coluna 'DATA INICIAL' **possui espaço**, não é possível acessá-la como método: `data.DATA INICIAL`"""

# selecionando múltiplas colunas: 'PRODUTO', 'ESTADO', 'REGIÃO'
data[['PRODUTO', 'ESTADO', 'REGIÃO']]

"""### 1.6 Removendo um Atributo (Coluna) do Data Frame"""

data.head()

"""Como vimos anteriormente, o atributo 'Unnamed: 0' parece ser um **ruído** em nosso dataset. Desta maneira, vamos eliminá-lo,"""

# deleta/remove in-place (ou seja, no próprio dataframe) a coluna de rótulo 'Unnamed: 0'
del data['Unnamed: 0']

data

"""<br/>

Vamos agora remover as colunas fictícias criadas nos vídeos para estudo.
"""

del data['coluna sem nocao']
del data['coluna a partir de lista']
del data['PREÇO MÉDIO REVENDA (dólares)']

data.head()

"""### 1.7 Salvando um Data Frame

Para salvarmos um Data Frame para um **arquivo CSV**, basta usarmos o método `.to_csv`. <br/>
Por padrão, esse método **salva os índices da tabela como uma coluna no CSV**.<br/>
Como no geral tais índices são números de 0 a n-1, não há necessidade para isso (veja que removemos anteriormente a coluna 'Unnamed: 0' que foi justamente esse caso).<br/>
Desta forma, utilize o parâmetro: `index=False`.

Por padrão, o método utilizará a ',' como separador das colunas. Caso queira alterá-lo, utilize o parâmetro `sep`.
"""

data.to_csv('./datasets/GasPricesinBrazil_2004-2019_preprocessado.csv', index=False)

"""### 1.8 Seleção Condicional: Filtrando amostras

Durante nossas análise exploratórias, frequentemente filtraremos nossas amostras, a partir de certas **condições**, para fins de análise mais específica. <br/>
Existem algumas maneiras de fazermos tal filtragem. Antes disso, vamos carregar nosso dataset pré-processado que salvamos no item anterior.
"""

data = pd.read_csv('./datasets/GasPricesinBrazil_2004-2019_preprocessado.csv')

data.head()

# Mostra todos os estados cujos os preços dos combustíveis foram aferidos
# Mais tecnicamente, mostra os valores únicos presentes para o atributo/coluna 'ESTADO'.
data['ESTADO'].unique()

"""#### **Selecionando apenas os preços dos Postos de São Paulo**

##### **==> Alternativa 1: Seleção Condicional (Comparações diretas)**

O código abaixo retorna uma ***Series ('array') de booleans***, com o número de linhas (observações) do Data Frame, que informa os registros de preços dos postos do _estado de São Paulo_ (True).
"""

# faz uma comparação elemento a elemento da series, retornando uma Series de booleans
data['ESTADO'] == 'SAO PAULO'

# salvando essa Series de booleans em uma variável
selecao = data['ESTADO'] == 'SAO PAULO'

selecao

type(selecao)

selecao.shape

data.shape

"""Para **filtrarmos** os registros de postos do estado de São Paulo:"""

data[selecao]

"""O resultado é um Data Frame com _apenas_ os registros desejados após a **filtragem**.<br/>
Podemos ainda utilizar o método `loc` para o mesmo fim:
"""

data.loc[selecao]

"""##### **==> Alternativa 2: Utilizando o método `query`**

`query` filtra linhas de um DataFrame baseado em uma **query (pergunta)**.
"""

data.head()

data.query('ESTADO == "SAO PAULO"')

"""<br/>

Uma boa prática é **salvar o Data Frame filtrado em uma nova variável**. Isso simplifica a complexidade do código para futuras análises feitas para os postos de São Paulo (neste caso).
"""

postos_sp = data.query('ESTADO == "SAO PAULO"')

postos_sp

type(postos_sp)

postos_sp.shape

postos_sp

"""#### Resetando os índices

Note que os _índices das linhas/registros_ após a _filtragem_ **continuam sendo os mesmos** do DataFrame original. <br/>
Em muitas situações, manter esta informação será importante.

Mas, se você quiser **_resetar os índices_** do data frame filtrado, fazendo com que os registros começem com _índice 0 até num_linhas-1_, use o método `.reset_index`.
"""

postos_sp.reset_index()

postos_sp.reset_index(drop=True)

# ainda não foi alterado, precisamos usar o atributo/parâmetro inplace=True
postos_sp

postos_sp.reset_index(drop=True, inplace=True)

postos_sp

# ALTERNATIVA MUITO COMUM
postos_sp = data.query('ESTADO == "SAO PAULO"').reset_index(drop=True)

postos_sp

"""#### **Selecionando registros de postos do Rio de Janeiro com Preços acima de 2 reais**"""

data.head()

data['ESTADO'] == 'RIO DE JANEIRO'

data['PREÇO MÉDIO REVENDA'] > 2.0

selecao = (data['ESTADO'] == 'RIO DE JANEIRO') & (data['PREÇO MÉDIO REVENDA'] > 2.0)
selecao

"""Note que o resultado da seleção continua sendo uma _Series de booleans_ com o _mesmo número de linhas/observações do DataFrame_, de modo que cada linha possuirá um valor booleano indicando se o posto é do Rio de Janeiro **E** o preço aferido do combustível é maior que 2 reais (True) ou não.

O símbolo **&** significa **AND** na comparação. Essa nomenclatura do python/pandas é diferente das nomenclaturas tradicionais (&&). <br/>
Similarmente:
- **|** representa o **OR** (não é ||)
- **~** representa o **NOT** (não é !)
"""

data[selecao]

"""Alternativamente, poderíamos usar o método `query` para fazermos tal seleção. Porém, isso não é possível especificamente para esse caso, pois o rótulo da coluna 'PREÇO MÉDIO REVENDA' possui caracteres inválidos para o método (cedilha, acentos) """

# Não funciona
# data.query('ESTADO=="RIO DE JANEIRO" and PREÇO MÉDIO REVENDA > 2')

data.query('ESTADO == "RIO DE JANEIRO" or ESTADO == "SAO PAULO"')

"""**Aprofundando mais ainda**

A primeira comparação `(data['ESTADO'] == 'RIO DE JANEIRO')` checa, linha a linha (observação a observação) do DataFrame, quais são aquelas cujo o estado é RIO DE JANEIRO. Nenhuma averiguação de preços é feita nesse momento. Como resultado, temos uma Series de booleans que responde **apenas** a essa "pergunta" feita.

A segunda comparação `(data['PREÇO MÉDIO REVENDA'] > 2)` checa, linha a linha (observação a observação) do DataFrame, quais são os registros cujo preço do combustível é maior que 2 reais. Note que essa comparação checará os postos de **TODOS os estados**. Como resultado, temos uma Series de booleans que responde **apenas** a essa "pergunta" feita.

Por fim, as duas "perguntas" são unidas pelo AND (&) que retorna a "pergunta completa" que fizemos.

Alguns podem argumentar que tal abordagem é **ineficiente**, uma vez que, para cada condição ("pergunta"), estamos varrendo todas as linhas do DataFrame. <br/>
O Pandas _tenta otimizar_ isso ao máximo por de trás dos panos. Mas, de fato, se tivermos um dataset **muito grande** (centenas de milhares de linhas), tal abordagem se tornará _lenta_.

Assim, poderíamos fazer filtragem com múltiplos condicionais em partes:
"""

selecao_1 = data['ESTADO'] == 'RIO DE JANEIRO'
postos_rj = data[selecao_1]
postos_rj

selecao_2 = postos_rj['PREÇO MÉDIO REVENDA'] > 2
selecao_2

postos_rj_preco_maior_que_2 = postos_rj[selecao_2]
postos_rj_preco_maior_que_2

"""#### **Selecionando registros de postos de São Paulo ou do Rio de Janeiro com Gasolina Comum acima de 2 reais**

Podemos fazer a solução do "jeito mais lento", percorrendo o DataFrame inteiro _múltiplas vezes_:
"""

data.head()

selecao_1 = (data['ESTADO'] == 'SAO PAULO') | (data['ESTADO'] == 'RIO DE JANEIRO')
selecao_2 = (data['PRODUTO'] == 'GASOLINA COMUM')
selecao_3 = (data['PREÇO MÉDIO REVENDA'] > 2)

selecao_final = selecao_1 & selecao_2 & selecao_3

selecao_final

data_filtrado = data[selecao_final]
data_filtrado

print(data_filtrado['ESTADO'].unique())
print(data_filtrado['PRODUTO'].unique())

"""<br/>

Alternativamente:
"""

selecao_1 = (data['ESTADO'] == 'SAO PAULO') | (data['ESTADO'] == 'RIO DE JANEIRO')
postos_sp_rj = data[selecao_1]

# apenas registros de postos dos estados de SP e RJ
postos_sp_rj

selecao_2 = (postos_sp_rj['PRODUTO'] == 'GASOLINA COMUM')
postos_sp_rj_gasolina = postos_sp_rj[selecao_2]

# apenas registros de postos dos estados de SP e RJ cujo produto é GASOLINA COMUM
postos_sp_rj_gasolina

selecao_3 = (postos_sp_rj_gasolina['PREÇO MÉDIO REVENDA'] > 2)

postos_sp_rj_gasolina_preco_maior_que_2 = postos_sp_rj_gasolina[selecao_3]
postos_sp_rj_gasolina_preco_maior_que_2

"""#### **Selecionando registros dos anos de 2008, 2010 e 2012**"""

data.head()

"""**ALTERNATIVA 1**"""

selecao = (data['ANO'] == 2008) | (data['ANO'] == 2010) | (data['ANO'] == 2012)
data[selecao]

"""**ALTERNATIVA 2**"""

lista_de_anos = [2008, 2010, 2012]

selecao = data['ANO'].isin(lista_de_anos)  # retorna uma Series de booleanos
data[selecao]

"""**ALTERNATIVA 3**"""

lista_de_anos

data.query('ANO in @lista_de_anos')

"""### **Iterando com DataFrames**

#### For-each `DataFrame.iterrows()` (LENTO ==> apenas indicado para iterar pequenos conjunto de dados)
"""

data.head(10)

for index, row in data.head(10).iterrows():
    print(f'indice {index} ==> {row["ESTADO"]}')

"""<h2>2. Preparação dos dados</h2>
<hr/>
"""

data

"""### 2.1 Tratando observações com valores vazios (null / nan) no dataset"""

data.info()

"""De um total de 106823 observações, **não há valores null / nan** para nenhum atributo. Mas, veremos que não é bem assim neste caso específico.<br/><br/>

### 2.2 Conversão de tipos de atributos

O pandas automaticamente reconhece os tipos de dados de cada coluna. <br/>
Porém, existem alguns atributos que estão com seus tipos errados: P. ex., "PREÇO MÉDIO DISTRIBUIÇÃO" deveria ser ```float64``` e não ```object```.<br/>
Nestes casos, muito provavelmente alguns registros têm uma string ao invés de um número para tais atributos. <br/>

Os atributos *"DATA INICIAL"* e *"DATA FINAL"* deveriam ser do tipo `datetime`.

Em outros casos, alguns **atributos categóricos** são ```objects```, mas poderiam ser o tipo ```category```, que é um tipo especial do pandas. <br/>
Este tipo é necessário para se utilizar algumas funções específicas do pandas. <br/>
**Não** converteremos para este tipo por ora.
"""

data_pre = data.copy()

"""#### **Datas**
Como os atributos de data do dataset já estão em um formato de data aceitável (YYYY-MM-DD), não precisamos forçar nenhuma conversão nesse sentido.
"""

data_pre['DATA INICIAL'] = pd.to_datetime(data_pre['DATA INICIAL'])
data_pre['DATA FINAL'] = pd.to_datetime(data_pre['DATA FINAL'])

data_pre.info()

"""#### **Dados Numéricos**"""

# convertendo atributos/colunas para 'numeric'
for atributo in ['MARGEM MÉDIA REVENDA', 'PREÇO MÉDIO DISTRIBUIÇÃO', 'DESVIO PADRÃO DISTRIBUIÇÃO', 'PREÇO MÍNIMO DISTRIBUIÇÃO', 'PREÇO MÁXIMO DISTRIBUIÇÃO', 'COEF DE VARIAÇÃO DISTRIBUIÇÃO']:
    # converte a coluna (de valores string) para um tipo numérico
    # Em caso de erro na conversão (p. ex., uma string que não representa um número), um valor vazio (null / nan) será
    # atribuído no lugar
    data_pre[atributo] = pd.to_numeric(data_pre[atributo], errors='coerce')

data_pre.info()

"""<br/>

Note que temos vários valores ***null*** agora **após a *conversão de tipos***. Vamos checá-los com mais cuidado nos dados originais e preprocessados.

### 2.3 Limpeza de dados
"""

mask = data_pre['PREÇO MÉDIO DISTRIBUIÇÃO'].isnull()

data_pre[mask]

# Nos dados originais, quais eram os valores do PREÇO MÉDIO DISTRIBUIÇÃO dos registros que agora possuem valores NaN 
data[mask]

"""Várias amostras possuem a _string '-'_ em algumas colunas ao invés de um número de fato. Ou seja, não há aferições destes atributos para estas amostras. <br/>

<br/>

Poderíamos **preencher os valores NaN com um valor padrão**. Para isso, basta usar o método `.fillna`.
"""

# Retorna uma cópia do data fram `data_pre` com todos os valores NaN de todas as colunas agora preenchidos com 0.
# Para alterar o próprio data frame, use o argumento `inplace=True`.
data_pre_fill = data_pre.fillna(0)
data_pre_fill

data_pre_fill[mask]  # valores que antes eram NaN, agora são 0

# retorna uma cópia do data frame `data_pre` com todos os valores NaN das colunas:
# 'PREÇO MÉDIO DISTRIBUIÇÃO', 'DESVIO PADRÃO DISTRIBUIÇÃO', 'PREÇO MÍNIMO DISTRIBUIÇÃO' e 'PREÇO MÁXIMO DISTRIBUIÇÃO', respectivamente, com os valores: 10, 20, 30, 'vazio'.
data_pre_fill = data_pre.fillna(value={
    'PREÇO MÉDIO DISTRIBUIÇÃO': 10,
    'DESVIO PADRÃO DISTRIBUIÇÃO': 20,
    'PREÇO MÍNIMO DISTRIBUIÇÃO': 30,
    'PREÇO MÁXIMO DISTRIBUIÇÃO': 'vazio'
})

data_pre_fill[mask]

"""<br/>

Por mais que a função `fillna` seja interessante e útil em muitos casos, no problema em questão estamos interessados em analisar precisamente, p. ex., o **'PREÇO MÉDIO DISTRIBUIÇÃO'**.<br/>
A fim de não termos valores _sintéticos_ gerados pelo `fillna`, que possam atrapalhar nossa análise, iremos **remover (drop) todas as amostras que possuem qualquer valor NaN** para quaisquer atributos/colunas. <br/>

Para isso, basta utilizarmos o método `dropna`.
"""

# remove, no próprio dataframe, todas as linhas/registros com valores NaN (vazios) em quaisquer colunas/atributos.
data_pre.dropna(inplace=True)

data_pre.info()

"""Nosso data frame agora, após essa _limpeza_, ficou mais enxuto, contentdo 103392 registros frente aos 106823 registros originais. <br/>

Essas são apenas algumas das possíveis _técnicas de limpeza de dados_. Outras estratégias, p. ex., **confiam na detecção de outliers**, que não veremos neste curso.

#### **Salvando o Dataset Preprocessado**
"""

data_pre.to_csv(dirBase+'/datasets/GasPricesinBrazil_2004-2019_preprocessado_final.csv', index=False)

"""<h2>3. Estatísticas Descritivas</h2>
<hr/>
"""

data_final = pd.read_csv(dirBase+'/datasets/GasPricesinBrazil_2004-2019_preprocessado_final.csv')

data_final

"""O Pandas fornecem algumas funções/métodos que computam certas estatísticas descritivas.

`describe`: exibe várias **estatísticas descritivas** para os _atributos_ de um dataframe ou para uma _Series_.
"""

data_final.describe()

data_final['PREÇO MÉDIO REVENDA'].describe()

"""<br/>

Como o resultado do `describe` de um _dataframe_ é outro _dataframe_, podemos filtrar apenas algumas colunas.
"""

data_final.describe()['PREÇO MÉDIO REVENDA']

stats = data_final.describe()
stats

stats[['PREÇO MÉDIO REVENDA', 'PREÇO MÁXIMO REVENDA', 'PREÇO MÉDIO DISTRIBUIÇÃO']]

# ALTERNATIVA MAIS EFICIENTE
# apenas computa as estatísticas descritivas para 3 atributos
data_final[['PREÇO MÉDIO REVENDA', 'PREÇO MÁXIMO REVENDA', 'PREÇO MÉDIO DISTRIBUIÇÃO']].describe()

"""**Acessando apenas algumas estatísticas**"""

stats

stats.loc[['min', 'max', 'mean']]

stats.loc[['min', 'max', 'mean'], 'PREÇO MÉDIO REVENDA']

stats.loc[['min', 'max', 'mean'], ['PREÇO MÉDIO REVENDA', 'PREÇO MÉDIO DISTRIBUIÇÃO']]

"""<br/>

`mean`, `std`, `min`, etc: cada uma das estatísticas do `describe` podem ser computadas individualmente:
"""

data_final.head()

"""#### Qual é o menor preço mínimo de revenda?"""

data_final['PREÇO MÍNIMO REVENDA'].min()

"""#### Qual é a média e desvio padrão dos preços mínimos de revenda?"""

mean = data_final['PREÇO MÍNIMO REVENDA'].mean()
std = data_final['PREÇO MÍNIMO REVENDA'].std()

print(f'A média dos preços mínimos de revenda é {mean:.2f} +- {std:.2f}')

"""#### Quais são os estados considerados?"""

data_final['ESTADO']

data_final['ESTADO'].unique()

sorted(data_final['ESTADO'].unique())

"""#### Quantos registros (aferições) cada estado possui?

`.value_counts()`:  Conta a frequência dos valores de uma dada variável (de preferência, _categórica_).
"""

data_final['ESTADO'].value_counts()  # retorna em ordem decrescente, a quantidade de registros/linhas para cada estado

data_final['ESTADO'].value_counts().to_frame()  # converte uma Series para um DataFrame

"""<h2>4. Executando funções para cada item de um DataFrame ou Series</h2>
<hr/>

Uma alternativa ao `for-loop` que vimos anteriormente e que é _lento_, é usarmos _funções próprias do pandas_ que **aplicam/mapeiam uma dada função a todos os elementos de um DataFrame ou Series**, retornando novos elementos "transformados".

<img src='./imagens/apply_map_applymap.png' width=300/>


Fonte: https://towardsdatascience.com/introduction-to-pandas-apply-applymap-and-map-5d3e044e93ff
"""

df = pd.DataFrame({ 'A': [1, 2, 3, 4], 
                    'B': [10, 20, 30, 40],
                    'C': [100, 200, 300, 400]}, 
                     index=['Linha 1', 'Linha 2', 'Linha 3', 'Linha 4'])

df

"""`apply()`: usado para aplicar uma função ao longo de um eixo de um DataFrame ou em valores de uma Series.

<img src='./imagens/pandas_axis.jpg' width=500/>

Fonte: https://www.allthesnippets.com/browse/pandas/df_axis.html
"""

def nossa_soma(series):
    return series.sum()  # retorna a soma de todos os valores de uma series

# aplica a função soma para cada linha do dataframe
df['SOMA(A, B, C)'] = df.apply(nossa_soma, axis=1)
df

"""<img src='./imagens/apply_axis_1.png' width=250/>"""

# aplica a função soma para cada coluna do dataframe
df.loc['Linha 5'] = df.apply(nossa_soma, axis=0)
df

"""<img src='./imagens/apply_axis_0.png' width=250/>

##### Usando `lambda` functions
"""

df['MEDIA(A, B, C)'] = df[['A', 'B', 'C']].apply(lambda series: series.mean(), axis=1)
df

"""<img src='./imagens/apply_axis_1_mean.png' width=350/>"""

# plica a lambda function abaixo para cada elemento da coluna
df['C * 2'] = df['C'].apply(lambda x: x * 2)
df

df['A * 2'] = df['A'] * 2
df

"""<br/>

`applymap()`: usado para aplicar uma função para **cada elemento** (_element-wise_) de um DataFrame.
"""

df = pd.DataFrame({ 'A': [1, 2, 3, 4], 
                    'B': [10, 20, 30, 40],
                    'C': [100, 200, 300, 400]}, 
                     index=['Linha 1', 'Linha 2', 'Linha 3', 'Linha 4'])
df

# retorna um novo dataframe com todos os elementos ao quadrado.
# poderíamos usar uma função ao invés de uma lambda function
df.applymap(lambda x: x ** 2)

df

"""<br/>

`map()`: usado para aplicar uma função para **cada elemento** (_element-wise_) de uma _Series_.
"""

nomes = pd.Series(['João', 'Maria', 'Alice', 'Pedro'])
nomes

# retorna uma nova Series com todos os nomes com letras maiuscúlas.
# poderíamos usar uma função ao invés de uma lambda function
nomes.map(lambda x: x.upper())

nomes

# O Pandas já fornece uma série de métodos para manipulação de strings.
# Assim, poderíamos usar o código abaixo para obter o mesmo resultado.
nomes.str.upper()

"""<h2>5. Agrupamento</h2>
<hr/>
"""

data_final.head()

"""`groupby`: Usado para criar **grupos de elementos** (e.x., baseado nos valores de um atributo (categórico)). <br/>
**Funções** podem então ser aplicadas para os _elementos de cada grupo_, de modo que os **resultados de cada grupo são combinados**.
"""

# agrupa as linhas da tablea de acordo com suas respectivas regiões
grupos = data_final.groupby('REGIÃO')
grupos

# retorna os grupos obtidos pelo groupby
grupos.groups

# retorna os índices das linhas/observações de cada grupo
grupos.indices

# retorna um dataframe apenas com as observações do grupo 'CENTRO OESTE'
grupos.get_group('CENTRO OESTE')

# descreva para nós algumas estatística descritivas para as observações de cada grupo
grupos.describe()

grupos.mean()

grupos.min()

data_final.groupby('REGIÃO').min()

"""<br/>

Também podemos ter agrupamentos por mais de um atributo.
"""

data_final.head()

"""#### Qual é o preço médio de cada do Produto (Combustível) para cada Região?"""

# Agrupa os registros do dataframe primeiramente por suas regiões.
# Então, agrupa os registros de cada região (grupo) de acordo com seus produtos.
grupos = data_final.groupby(['REGIÃO', 'PRODUTO'])
grupos

grupos.groups

grupos.mean()

grupos['PREÇO MÉDIO REVENDA'].mean()

grupos['PREÇO MÉDIO REVENDA'].describe()

"""<br/>

`.agg`: **agrega (roda)** uma série de funções para os elementos de um dataframe ou de grupos de um dataframe.
"""

df = pd.DataFrame([[1, 2, 3],
                   [4, 5, 6],
                   [7, 8, 9],
                   [None, None, None]],
                  columns=['A', 'B', 'C'])
df

df.agg([sum, min])  # ignora o NaN

grupos = data_final.groupby('REGIÃO')
grupos

# Computa o menor e maior valor do 'PREÇO MÉDIO REVENDA' para cada região (grupo)
grupos['PREÇO MÉDIO REVENDA'].agg([min, max])

"""<h2>6. Ordenação</h2>
<hr/>
"""

notas = pd.DataFrame({
    'nome': ['João', 'Maria', 'José', 'Alice'],
    'idade': [20, 21, 19, 20],
    'nota_final': [5.0, 10.0, 6.0, 10.0]
})
notas

"""`.sort_values()`: ordena valores ao longo de um eixo."""

notas.sort_values(by='nota_final')

"""Por padrão, o método retorna uma cópia dos dados ordenados em **ordem crescente (ascendente)**. Podemos alterar isso pelo argumento `ascending`."""

notas.sort_values(by='nota_final', ascending=False)

"""<br/>

Podemos ordenar a partir de **mais de uma coluna**:
"""

notas.sort_values(by=['nota_final', 'nome'], ascending=[False, True])

"""Ordena os registros, primeiramente, pela coluna 'nota_final' em **ordem descrente**. <br/>
Então, reordena os registros _"empatados"_, ou seja, com a **mesma nota final**, em _ordem alfabética_ (ordem crescente).

<br/>

Note que o dataframe original **não foi alterado** após a ordenação.
"""

notas

"""Para alterá-lo, use o argumento `inplace=True`:"""

notas.sort_values(by=['nota_final', 'nome'], ascending=[False, True], inplace=True)

notas

"""<h2>7. Exercícios</h2>
<hr/>

Vamos aplicar os conceitos que vimos em alguns exercícios. <br/>
Para isso, utilizaremos o dataset de _preços de combustíveis no Brasil_.
"""

data_final

"""Como há apenas medições de janeiro a junho para o ano de 2019, resolvemos **remover os dados** deste ano da análise."""

data_final.query('ANO != 2019')

"""Note que temos um novo dataframe com 99739 linhas."""

df = data_final.query('ANO != 2019')

df

"""### 7.1 Qual a quantidade de registros de cada produto em cada região?"""

grupos = df.groupby('PRODUTO')
grupos

grupos['REGIÃO'].value_counts().to_frame()

"""### 7.2 Como os preços da Gasolina Comum em São Paulo variaram em 2018?"""

gasolina_sp_2018 = df.query('PRODUTO == "GASOLINA COMUM" and ESTADO == "SAO PAULO" and ANO == 2018')
gasolina_sp_2018.head()

gasolina_sp_2018.shape

"""#### **Estatísticas Descritivas**"""

gasolina_sp_2018.describe()

gasolina_sp_2018['PREÇO MÉDIO REVENDA'].describe().to_frame()

"""### 7.3 Como os preços da Gasolina Comum e do Etanol em São Paulo variaram em 2018?"""

df.query('(PRODUTO == "GASOLINA COMUM" or PRODUTO == "ETANOL HIDRATADO") and ESTADO == "SAO PAULO" and ANO == 2018')

lista_de_estados = ["GASOLINA COMUM", "ETANOL HIDRATADO"]
df.query('PRODUTO in @lista_de_estados and ESTADO == "SAO PAULO" and ANO == 2018')

gasolina_etanol_sp_2018 = df.query('PRODUTO in ["GASOLINA COMUM", "ETANOL HIDRATADO"] and ESTADO == "SAO PAULO" and ANO == 2018')
gasolina_etanol_sp_2018

# considerando os preços do etanol e da gasolina juntos, teremos essas estatística descritivas 
gasolina_etanol_sp_2018['PREÇO MÉDIO REVENDA'].describe().to_frame()

gasolina_etanol_sp_2018.groupby('PRODUTO')['PREÇO MÉDIO REVENDA'].describe()

"""<h2>8. Assuntos para continuar os estudos</h2>
<hr/>

- join
- concat
- plot
- data cleaning
"""